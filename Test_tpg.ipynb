{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@copy right: Ryan Amer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from IPython.display import clear_output\n",
    "# imports to run OpenAI Gym in Jupyter\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "# import to do training\n",
    "from tpg.tpg_trainer import TpgTrainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.tpg_agent import TpgAgent\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# transforms the state into what the tpg agent can use.\n",
    "# From 3D to 1D, taking only red data (from rgb array)\n",
    "def getState(state):\n",
    "    state2 = []\n",
    "    for x in state:\n",
    "        for y in x:\n",
    "            state2.append(y[0])\n",
    "            \n",
    "    return state2\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "\n",
    "# run agent in function to work with multiprocessing\n",
    "def runAgent(agenteqsq):\n",
    "    agent = agenteqsq[0] # get agent\n",
    "    eq = agenteqsq[1] # get environment queue\n",
    "    sq = agenteqsq[2] # get score queue\n",
    "    \n",
    "    # check if agent already has score\n",
    "    if agent.taskDone():\n",
    "        sq.put((agent.getUid(), agent.getOutcomes()))\n",
    "        return\n",
    "        \n",
    "    env = eq.get() # get an environment\n",
    "    state = env.reset() # get initial state and prep environment\n",
    "    score = 0\n",
    "    for i in range(agenteqsq[3]): # run episodes that last 200 frames\n",
    "        act = agent.act(getState(state)) # get action from agent\n",
    "\n",
    "        # feedback from env\n",
    "        state, reward, isDone, debug = env.step(act)\n",
    "        score += reward # accumulate reward in score\n",
    "        if isDone:\n",
    "            break # end early if losing state\n",
    "            \n",
    "    lock.acquire() # may not actually need, mp is weird in python\n",
    "    agent.reward(score) # must reward agent\n",
    "    lock.release()\n",
    "    \n",
    "    sq.put((agent.getUid(), agent.getOutcomes())) # get outcomes with id\n",
    "    eq.put(env) # put environment back\n",
    "    \n",
    "def gamebegin(generation,gametitle,processes,frames, rs, tpopsize, rtpopSize,\n",
    "            curr_gap, pLearnerD, pLearnerA, pMutation,\n",
    "            pAIT, mts, mps,\n",
    "            ppd, ppa, pps,\n",
    "            ppm, ppit, tgap,\n",
    "            ar):\n",
    "    \n",
    "    action = env.action_space.n # get number of game action space\n",
    "\n",
    "    tStart = time.time()\n",
    "\n",
    "    lock = mp.Lock()\n",
    "\n",
    "    trainer = TpgTrainer(actions=action, randSeed=rs, teamPopSize=tpopsize, rTeamPopSize=rtpopSize,\n",
    "                    gap=curr_gap, pLearnerDelete=pLearnerD, pLearnerAdd=pLearnerA, pMutateAction=pMutation,\n",
    "                    pActionIsTeam=pAIT, maxTeamSize=mts, maxProgramSize=mps,\n",
    "                    pProgramDelete=ppd, pProgramAdd=ppa, pProgramSwap=pps,\n",
    "                    pProgramMutate=ppm, popInit=ppit, tourneyGap=tgap,\n",
    "                    actionRange=ar)\n",
    "\n",
    "\n",
    "    m = mp.Manager()\n",
    "    envQueue = m.Queue()\n",
    "    # each process needs its own environment\n",
    "    for i in range(processes):\n",
    "        envQueue.put(gym.make(gametitle))\n",
    "\n",
    "    pool = mp.Pool(processes=processes)\n",
    "\n",
    "    summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "\n",
    "    for gen in range(generation): # generation loop\n",
    "        scoreQueue = m.Queue() # hold agents when finish, to actually apply score\n",
    "\n",
    "        # run generation\n",
    "        # skipTasks=[] so we get all agents, even if already scored,\n",
    "        # just to report the obtained score for all agents.\n",
    "        pool.map(runAgent, \n",
    "                     [(agent, envQueue, scoreQueue,frames) \n",
    "                      for agent in trainer.getAllAgents(skipTasks=[])])\n",
    "\n",
    "        scores = [] # convert scores into list\n",
    "        while not scoreQueue.empty():\n",
    "            scores.append(scoreQueue.get())\n",
    "\n",
    "        # apply scores\n",
    "        trainer.applyScores(scores)\n",
    "        trainer.evolve(tasks=[]) # go into next gen\n",
    "\n",
    "        # at end of generation, make summary of scores\n",
    "        summaryScores.append((trainer.scoreStats['min'], \n",
    "                        trainer.scoreStats['max'],\n",
    "                        trainer.scoreStats['average'])) # min, max, avg\n",
    "        print(summaryScores[len(summaryScores)-1])\n",
    "    return summaryScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "test 1\n",
    "- generation , 20 loops\n",
    "\"\"\"\n",
    "generation = 20 # number of generations\n",
    "gametitle = 'Assault-v0'\n",
    "processes = 6 # how many to run concurrently (4 is best for my local desktop)\n",
    "frames = 100 #total frames each play\n",
    "tpopsize = 100 #teamPopSize\n",
    "rtpopSize = 0 #rTeamPopSize\n",
    "rs = 0 #randseed\n",
    "curr_gap = 0.5 #gap\n",
    "tgap = 0.5 #tourneyGap\n",
    "pLearnerD = 0.7 #learner delete\n",
    "pLearnerA = 0.7 #learner add\n",
    "pMutation = 0.2 #player mutation rate\n",
    "pAIT = 0.5 #pActionIsTeam\n",
    "mts = 5\n",
    "#maxTeamSize\n",
    "mps = 96 #maxProgramSize\n",
    "ppd = 0.5 #pProgramDelete\n",
    "ppa = 0.5 #pProgramAdd\n",
    "pps = 1.0 #pProgramSwap\n",
    "ppm = 1.0 #pProgramMutate\n",
    "ppit = None #popInit\n",
    "ar = (0.0, 1.0, 0.05) #actionRange\n",
    "\n",
    "\n",
    "summary = gamebegin(generation,gametitle,processes,frames, rs, tpopsize, rtpopSize,\n",
    "            curr_gap, pLearnerD, pLearnerA, pMutation,\n",
    "            pAIT, mts, mps,\n",
    "            ppd, ppa, pps,\n",
    "            ppm, ppit, tgap,\n",
    "            ar)\n",
    "#legend\n",
    "trace1 = go.Scatter(x=[i for i in range(len(summary))],y=[i[0] for i in summary],name='min')\n",
    "trace2 = go.Scatter(x=[i for i in range(len(summary))],y=[i[1] for i in summary],name='max')\n",
    "trace3 = go.Scatter(x=[i for i in range(len(summary))],y=[i[2] for i in summary],name='average')\n",
    "data = [trace1,trace2,trace3]\n",
    "layout = go.Layout(showlegend=True,legend={'x':0.2,'y':0.6})\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
